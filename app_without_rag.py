import os
import streamlit as st
from dotenv import load_dotenv
import google.generativeai as gen_ai
import time
from gemini_rag import QASystem
load_dotenv()

st.set_page_config(
    page_title="Chat with Gemini-Pro!",
    page_icon="â›µ",
    layout="centered",
)

GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

gen_ai.configure(api_key=GOOGLE_API_KEY)
model = gen_ai.GenerativeModel('gemini-pro')


def translate_role_for_streamlit(user_role):
    if user_role == "model":
        return "assistant"
    else:
        return user_role


# Function to start a new chat session
def start_chat_session(session_key):
    if session_key not in st.session_state:
        st.session_state[session_key] = model.start_chat(history=[])

def get_function_icon(function_title):
    icons = {
        "Äá»‹a Ä‘iá»ƒm": ' ğŸŒ',
        "áº¨m thá»±c": ' ğŸ½ï¸ğŸ´',
        "TÆ° váº¥n": ' ğŸ¤”',
        "Cáº©m nang": ' ğŸ“š',
        "Thá»i tiáº¿t vÃ  Ä‘iá»u kiá»‡n giao thÃ´ng": ' ğŸš¥â›…'
    }
    return icons.get(function_title, '')
# Function to display chat interface
def chat_interface(session_key, chat_history_key, function_title):
    start_chat_session(session_key)

    st.header(function_title + get_function_icon(function_title))

    chat_session = st.session_state[session_key]

    for message in chat_session.history:
        with st.chat_message(translate_role_for_streamlit(message.role)):
            st.markdown(message.parts[0].text)
    user_prompt = st.chat_input(f"Há»i tÃ´i vá» {function_title}...")

    if user_prompt:
        st.chat_message("user").markdown(user_prompt)
        if(session_key == "chat_session_locations"):
            user_prompt_full = 'Äá»‹a Ä‘iá»ƒm du lá»‹ch á»Ÿ:' + user_prompt
        elif(session_key == 'chat_session_cuisine'):
            user_prompt_full = ' má»™t sá»‘ nhÃ  hÃ ng, áº©m thá»±c á»Ÿ: ' + user_prompt
        elif(session_key == 'chat_session_advice'):
            user_prompt_full = 'TÆ° váº¥n du lá»‹ch cho tÃ´i vá»: ' + user_prompt
        elif(session_key == 'chat_session_guide'):
            user_prompt_full = 'Má»™t vÃ i cáº©m nang khi du lá»‹ch á»Ÿ :' + user_prompt
        else:
            user_prompt_full = user_prompt

        gemini_response = chat_session.send_message(user_prompt_full)

        # Display Gemini-Pro's complete response after typing effect
        tmp_str = ""
        with st.chat_message("assistant"):
            typing_placeholder = st.empty()
            for char in gemini_response.text:
                tmp_str  = tmp_str + char
                time.sleep(0.01)  # Thá»i gian delay giá»¯a cÃ¡c kÃ½ tá»±
                typing_placeholder.markdown(tmp_str)
            st.markdown(gemini_response.text)


# Main program
st.title("ğŸ¤– Trá»£ lÃ½ du lá»‹ch áº£o")

menu = ["Trang chá»§", "Äá»‹a Ä‘iá»ƒm", "áº¨m thá»±c", "TÆ° váº¥n", "Cáº©m nang", "Thá»i tiáº¿t vÃ  Ä‘iá»u kiá»‡n giao thÃ´ng"]
choice = st.sidebar.selectbox("Chá»n chá»©c nÄƒng", menu)

if choice == "Trang chá»§":
    st.header("Trang chá»§")
    st.write("ChÃ o má»«ng báº¡n Ä‘áº¿n vá»›i trá»£ lÃ½ du lá»‹ch áº£o! Chá»n má»™t chá»©c nÄƒng tá»« menu bÃªn trÃ¡i.")

elif choice == "Äá»‹a Ä‘iá»ƒm":
    chat_interface("chat_session_locations", "chat_history_locations", "Äá»‹a Ä‘iá»ƒm")

elif choice == "áº¨m thá»±c":
    chat_interface("chat_session_cuisine", "chat_history_cuisine", "áº¨m thá»±c")

elif choice == "TÆ° váº¥n":
    chat_interface("chat_session_advice", "chat_history_advice", "TÆ° váº¥n")

elif choice == "Cáº©m nang":
    chat_interface("chat_session_guide", "chat_history_guide", "Cáº©m nang")

elif choice == "Thá»i tiáº¿t vÃ  Ä‘iá»u kiá»‡n giao thÃ´ng":
    st.header("Thá»i tiáº¿t vÃ  Ä‘iá»u kiá»‡n giao thÃ´ng  ğŸš¥â›…")
    st.write("Chá»©c nÄƒng táº¡m Ä‘Ã³ng!")
